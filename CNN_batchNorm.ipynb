{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata: done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/abhinavverma/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch-nightly\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.6.11               |           py37_0         1.7 MB\n",
      "    ninja-1.9.0                |   py37h04f5b5a_0          96 KB\n",
      "    pytorch-nightly-1.0.0.dev20190405|          py3.7_0        47.7 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        49.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ninja              pkgs/main/osx-64::ninja-1.9.0-py37h04f5b5a_0\n",
      "  pytorch-nightly    pytorch/osx-64::pytorch-nightly-1.0.0.dev20190405-py3.7_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                                        4.6.8-py37_0 --> 4.6.11-py37_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pytorch-nightly-1.0. | 47.7 MB   | ##################################### | 100% \n",
      "conda-4.6.11         | 1.7 MB    | ##################################### | 100% \n",
      "ninja-1.9.0          | 96 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! conda install pytorch-nightly -c pytorch --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The conda.compat module is deprecated and will be removed in a future release.\n",
      "\n",
      "PackagesNotFoundError: The following packages are missing from the target environment:\n",
      "  - pytorch\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda uninstall --force pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from exp.nb_Training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import datasets\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlowCalculator():\n",
    "    def __init__(self, cb=None): self.cb,self.res = cb,0\n",
    "    \n",
    "    def __call__(self, cb_name, *args):\n",
    "        if not self.cb: return\n",
    "        cb = getattr(self.cb,cb_name, None)\n",
    "        if cb: return cb(self,*args) #self stands for the instance of SlowCalculator()\n",
    "\n",
    "    def calc(self):\n",
    "        for i in range(5):\n",
    "            self('before_calc', i)\n",
    "            self.res += i*i\n",
    "            sleep(1)\n",
    "            if self('after_calc', i):\n",
    "                print(\"stopping early\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifyingCallback():\n",
    "    def after_calc (self, calc, epoch):\n",
    "        print(type(calc))\n",
    "        print(f\"After {epoch}: {calc.res}\")\n",
    "        if calc.res>10: return True\n",
    "        if calc.res<3: calc.res = calc.res*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = SlowCalculator(ModifyingCallback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.SlowCalculator'>\n",
      "After 0: 0\n",
      "<class '__main__.SlowCalculator'>\n",
      "After 1: 1\n",
      "<class '__main__.SlowCalculator'>\n",
      "After 2: 6\n",
      "<class '__main__.SlowCalculator'>\n",
      "After 3: 15\n",
      "stopping early\n"
     ]
    }
   ],
   "source": [
    "calculator.calc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gzip,pickle\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_URL = \"http://deeplearning.net/data/mnist/mnist.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
    "def normalize(x,m,s):\n",
    "    return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean,train_std = x_train.mean(),x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def normalize_to(train, valid):\n",
    "    m,s = train.mean(),train.std()\n",
    "    return normalize(train, m, s), normalize(valid, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid = normalize_to(x_train,x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completely generic function to change the size of the input vector to the size we want\n",
    "def view_tfm(*size):\n",
    "    print(*size)\n",
    "    def _inner(x): return x.view(*((-1,)+size))\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 28 28\n"
     ]
    }
   ],
   "source": [
    "inner = view_tfm(1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "??torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner(x_train).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a simple CNN learner layer fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh,bs = 50,512\n",
    "c = y_train.max().item()+1\n",
    "loss_func = F.cross_entropy\n",
    "bs = 64\n",
    "\n",
    "data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x): return self.func(x)\n",
    "\n",
    "def flatten(x):      return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_resize(x): return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(data):\n",
    "    return nn.Sequential(\n",
    "        Lambda(mnist_resize),\n",
    "        nn.Conv2d( 1, 8, 5, padding=2,stride=2), nn.ReLU(), #14\n",
    "        nn.Conv2d( 8,16, 3, padding=1,stride=2), nn.ReLU(), # 7\n",
    "        nn.Conv2d(16,32, 3, padding=1,stride=2), nn.ReLU(), # 4\n",
    "        nn.Conv2d(32,32, 3, padding=1,stride=2), nn.ReLU(), # 2\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Lambda(flatten),\n",
    "        nn.Linear(32,data.c)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [Recorder, partial(AvgStatsCallback,accuracy)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=0.4)\n",
    "learn = Learner(model, opt, loss_func, data)\n",
    "run = Runner(cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.402578828125, tensor(0.8687)]\n",
      "valid: [0.383096044921875, tensor(0.9036)]\n",
      "CPU times: user 20.2 s, sys: 2.89 s, total: 23.1 s\n",
      "Wall time: 7.88 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mac is very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(ni, nf, ks=3, stride=2):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ni, nf, ks, padding=ks//2, stride=stride), nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchTransformXCallback(Callback):\n",
    "    _order=2\n",
    "    def __init__(self, tfm): self.tfm = tfm\n",
    "    def begin_batch(self): self.run.xb = self.tfm(self.xb)\n",
    "\n",
    "def view_tfm(*size):\n",
    "    def _inner(x): return x.view(*((-1,)+size))\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_view = view_tfm(1,28,28)\n",
    "cbfs.append(partial(BatchTransformXCallback, mnist_view))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[exp.nb_Training.Recorder,\n",
       " functools.partial(<class 'exp.nb_Training.AvgStatsCallback'>, <function accuracy at 0x1a28961268>),\n",
       " functools.partial(<class '__main__.BatchTransformXCallback'>, <function view_tfm.<locals>._inner at 0x1a2895b378>)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs = [8,16,32,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_layers(data, nfs):\n",
    "    nfs = [1] + nfs\n",
    "    return [\n",
    "        conv2d(nfs[i], nfs[i+1], 5 if i==0 else 3)\n",
    "        for i in range(len(nfs)-1)\n",
    "    ] + [nn.AdaptiveAvgPool2d(1), Lambda(flatten), nn.Linear(nfs[-1], data.c)]\n",
    "\n",
    "def get_cnn_model(data, nfs): return nn.Sequential(*get_cnn_layers(data, nfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sequential(\n",
       "   (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "   (1): ReLU()\n",
       " ), Sequential(\n",
       "   (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "   (1): ReLU()\n",
       " ), Sequential(\n",
       "   (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "   (1): ReLU()\n",
       " ), Sequential(\n",
       "   (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "   (1): ReLU()\n",
       " ), AdaptiveAvgPool2d(output_size=1), Lambda(), Linear(in_features=32, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cnn_layers(data,nfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_runner(model, data, lr=0.6, cbs=None, opt_func=None, loss_func = F.cross_entropy):\n",
    "    if opt_func is None: opt_func = optim.SGD\n",
    "    opt = opt_func(model.parameters(), lr=lr)\n",
    "    learn = Learner(model, opt, loss_func, data)\n",
    "    return learn, Runner(cb_funcs=listify(cbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(data, nfs)\n",
    "learn,run = get_runner(model, data, lr=0.4, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn1,run1 = get_runner(model, data, lr=0.4, cbs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.469774453125, tensor(0.8426)]\n",
      "valid: [0.1129917724609375, tensor(0.9672)]\n",
      "train: [0.09288205078125, tensor(0.9717)]\n",
      "valid: [0.09296600952148437, tensor(0.9713)]\n",
      "train: [0.0712677978515625, tensor(0.9770)]\n",
      "valid: [0.3370674560546875, tensor(0.9073)]\n",
      "CPU times: user 1min, sys: 9.13 s, total: 1min 10s\n",
      "Wall time: 24.4 s\n"
     ]
    }
   ],
   "source": [
    "%time run.fit(3, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
