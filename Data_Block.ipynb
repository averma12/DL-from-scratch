{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rotten_tomatoes_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_names_to_idx(names, df):\n",
    "    \"Return the column indexes of `names` in `df`.\"\n",
    "    if not listify(names): names = [names]\n",
    "    if isinstance(names[0], int): return names\n",
    "    return [df.columns.get_loc(c) for c in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Freshness', 'Review'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_names_to_idx([\"Freshness\",\"Review\"],df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is1d(a:Collection)->bool:\n",
    "    \"Return `True` if `a` is one-dimensional\"\n",
    "    return len(a.shape) == 1 if hasattr(a, 'shape') else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maybe_squeeze(arr): return (arr if is1d(arr) else np.squeeze(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_df(df, path ='.', cols=0, processor=None, **kwargs):\n",
    "        \"Create an `ItemList` in `path` from the inputs in the `cols` of `df`.\"\n",
    "        inputs = df.iloc[:,df_names_to_idx(cols, df)]\n",
    "        assert inputs.isna().sum().sum() == 0, f\"You have NaN values in column(s) {cols} of your dataframe, please fix it.\"\n",
    "        res = _maybe_squeeze(inputs.values)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(df.iloc[:,[0,1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = df.iloc[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = _maybe_squeeze(inputs.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1,\n",
       "       \" Manakamana doesn't answer any questions, yet makes its point: Nepal, like the rest of our planet, is a picturesque but far from peaceable kingdom.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " \" Manakamana doesn't answer any questions, yet makes its point: Nepal, like the rest of our planet, is a picturesque but far from peaceable kingdom.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListContainer():\n",
    "    def __init__(self, items): self.items = listify(items)\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, (int,slice)): return self.items[idx]\n",
    "        if isinstance(idx[0],bool):\n",
    "            assert len(idx)==len(self) # bool mask\n",
    "            return [o for m,o in zip(idx,self.items) if m]\n",
    "        return [self.items[i] for i in idx]\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return iter(self.items)\n",
    "    def __setitem__(self, i, o): self.items[i] = o\n",
    "    def __delitem__(self, i): del(self.items[i])\n",
    "    def __repr__(self):\n",
    "        res = f'{self.__class__.__name__} ({len(self)} items)\\n{self.items[:10]}'\n",
    "        if len(self)>10: res = res[:-1]+ '...]'\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(x, funcs, *args, order_key='_order', **kwargs):\n",
    "    key = lambda o: getattr(o, order_key, 0)\n",
    "    for f in sorted(listify(funcs), key=key): x = f(x, **kwargs)\n",
    "    return x\n",
    "\n",
    "class ItemList(ListContainer):\n",
    "    def __init__(self, items, path='.', tfms=None):\n",
    "        super().__init__(items)\n",
    "        self.path,self.tfms = Path(path),tfms\n",
    "\n",
    "    def __repr__(self): return f'{super().__repr__()}\\nPath: {self.path}'\n",
    "    def new(self, items): return self.__class__(items, self.path, tfms=self.tfms)\n",
    "    \n",
    "    def  get(self, i): return i\n",
    "    def _get(self, i): return compose(self.get(i), self.tfms)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        (\"Getitem called\")\n",
    "        res = super().__getitem__(idx)\n",
    "        if isinstance(res,list): return [self._get(o) for o in res]\n",
    "        return self._get(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextList(ItemList):\n",
    "    @classmethod\n",
    "    def from_files(cls, path, extensions='.txt', recurse=True, include=None, **kwargs):\n",
    "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_df(cls,df, path ='.', cols=0, processor=None, **kwargs):\n",
    "        \"Create an `ItemList` in `path` from the inputs in the `cols` of `df`.\"\n",
    "        inputs = df.iloc[:,df_names_to_idx(cols, df)]\n",
    "        assert inputs.isna().sum().sum() == 0, f\"You have NaN values in column(s) {cols} of your dataframe, please fix it.\"\n",
    "        res = cls(_maybe_squeeze(inputs.values),path=path,**kwargs)\n",
    "        return res\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    def get(self, i):\n",
    "        if isinstance(i, Path): return read_file(i)\n",
    "        if isinstance(i,pd.DataFrame): return df.loc(i).tolist()\n",
    "        return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "il = TextList.from_df(df,cols=[\"Freshness\",\"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(il.items) - 96000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ItemList.new of TextList (480000 items)\n",
       "[array([1,\n",
       "       \" Manakamana doesn't answer any questions, yet makes its point: Nepal, like the rest of our planet, is a picturesque but far from peaceable kingdom.\"],\n",
       "      dtype=object), array([1,\n",
       "       \" Wilfully offensive and powered by a chest-thumping machismo, but it's good clean fun.\"],\n",
       "      dtype=object), array([0,\n",
       "       ' It would be difficult to imagine material more wrong for Spade than Lost & Found.'],\n",
       "      dtype=object), array([0,\n",
       "       \" Despite the gusto its star brings to the role, it's hard to ride shotgun on Hector's voyage of discovery.\"],\n",
       "      dtype=object), array([0,\n",
       "       \" If there was a good idea at the core of this film, it's been buried in an unsightly pile of flatulence jokes, dog-related bad puns and a ridiculous serial arson plot.\"],\n",
       "      dtype=object), array([0,\n",
       "       ' Gleeson goes the Hallmark Channel route, damaging an intermittently curious entry in the time travel subgenre.'],\n",
       "      dtype=object), array([1,\n",
       "       ' It was the height of satire in 1976: dark as hell, but patently absurd and surely nowhere close to objective reality. Objective reality surpassed it somewhere in the Jerry Springer era.'],\n",
       "      dtype=object), array([0,\n",
       "       ' Everyone in \"The Comedian\" deserves a better movie than \"The Comedian.\"'],\n",
       "      dtype=object), array([0, ' Actor encourages grumpy Christians to embrace the season.'],\n",
       "      dtype=object), array([1, ' Slight, contained, but ineffably soulful.'], dtype=object)...]\n",
       "Path: .>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il.new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(items,valid_pct = 0.2):\n",
    "    cut = int(valid_pct * len(items))\n",
    "    train_idxs = len(items) - cut\n",
    "    print(train_idxs)\n",
    "    train = items[:train_idxs]\n",
    "    valid = items[train_idxs:]\n",
    "    return train,valid\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SplitData():\n",
    "    def __init__(self, train, valid): self.train,self.valid = train,valid\n",
    "        \n",
    "    def __getattr__(self,k): return getattr(self.train,k)\n",
    "    #This is needed if we want to pickle SplitData and be able to load it back without recursion errors\n",
    "    def __setstate__(self,data:Any): self.__dict__.update(data) \n",
    "    \n",
    "    @classmethod\n",
    "    def split_by_func(cls, il, f):\n",
    "        lists = map(il.new,f)\n",
    "        return cls(*lists)\n",
    "\n",
    "    def __repr__(self): return f'{self.__class__.__name__}\\nTrain: {self.train}\\nValid: {self.valid}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = partial(split_df,il.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384000\n"
     ]
    }
   ],
   "source": [
    "sd = SplitData.split_by_func(il,splitter(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1,\n",
       "       \" Manakamana doesn't answer any questions, yet makes its point: Nepal, like the rest of our planet, is a picturesque but far from peaceable kingdom.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _label_from_list(self, labels:Iterator, label_cls:Callable=None, from_item_lists:bool=False, **kwargs)->'LabelList':\n",
    "        \"Label `self.items` with `labels`.\"\n",
    "        if not from_item_lists:\n",
    "            raise Exception(\"Your data isn't split, if you don't want a validation set, please use `split_none`.\")\n",
    "        labels = array(labels, dtype=object)\n",
    "        label_cls = self.get_label_cls(labels, label_cls=label_cls, **kwargs)\n",
    "        y = label_cls(labels, path=self.path, **kwargs)\n",
    "        res = self._label_list(x=self, y=y)\n",
    "        return res\n",
    "\n",
    "    def label_from_df(self, cols:IntsOrStrs=1, label_cls:Callable=None, **kwargs):\n",
    "        \"Label `self.items` from the values in `cols` in `self.inner_df`.\"\n",
    "        labels = self.inner_df.iloc[:,df_names_to_idx(cols, self.inner_df)]\n",
    "        assert labels.isna().sum().sum() == 0, f\"You have NaN values in column(s) {cols} of your dataframe, please fix it.\"\n",
    "        if is_listy(cols) and len(cols) > 1 and (label_cls is None or label_cls == MultiCategoryList):\n",
    "            new_kwargs,label_cls = dict(one_hot=True, classes= cols),MultiCategoryList\n",
    "            kwargs = {**new_kwargs, **kwargs}\n",
    "        return self._label_from_list(_maybe_squeeze(labels), label_cls=label_cls, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sd.train.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
